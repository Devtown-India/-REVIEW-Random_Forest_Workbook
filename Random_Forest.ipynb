{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests - Introduction:\n",
    "\n",
    "The Random Forest algorithm is a supervised machine learning algorithm that can be used for both classification and regression problems.The basic unit of a Random Forest model is a Decision Tree. As the name suggests, this algorithm randomly creates and merges multiple decision trees into one \"forest\". It uses *bagging* and *feature randomness* while building individual trees to try and create an **uncorrelated** forest whose prediction is more accurate than that of any individual tree.\n",
    "\n",
    "### Advantages of Random Forests:\n",
    "\n",
    "1. No overfitting of data.\n",
    "\n",
    "2. Can be used for both regression and classification problems unlike most other algorithms.\n",
    "\n",
    "3. Feature scaling not required.\n",
    "\n",
    "4. Robust to outliers.\n",
    "\n",
    "5. Comparatively less affected by noise.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests - Working:\n",
    "\n",
    "The fundamental idea behind a random forest, as mentioned above, is to combine many decision trees into a single model. Individually, predictions made by decision trees may not be accurate, but combined together, the prediction will be closer to the mark on average. This is because, predictions of individual trees ( if they are not overfit ) have variance, i.e, they are widely spread around the right answer. But, when multiple trees are combined together, the overall prediction almost always has lesser variance and higher accuracy.\n",
    "\n",
    "### Bagging ( Bootstrap Aggregation):\n",
    "Bootstrap Aggregation is a simple and very powerful ensemble method (a technique that combines the predictions from multiple machine learning algorithms together to make more accurate predictions than any individual model) that can be used to reduce the variance for those algorithm that have high variance.\n",
    "\n",
    "Consider a dataset consisting of 1000 samples(rows).Bagging works as follows:\n",
    "\n",
    "1. Create 100 subsets of the dataset.\n",
    "2. Train a decision tree model on each of those subsets.\n",
    "3. Calculate the average prediction.\n",
    "\n",
    "For example, If 5 different trees made the class predictions blue, blue, green, blue and red, the final prediction becomes blue.\n",
    "\n",
    "![alt text](./images/random_forest.JPG \"Title\")\n",
    "\n",
    "### Feature Randomness:\n",
    "The problem with using Bagging on Decision trees is that Decision trees are greedy. During splitting of a node, they choose which variable to split on using a greedy algorithm that minimizes error, i.e, they consider every possible feature and pick the one that produces the most separation between the observations in the left node vs. those in the right node. This means that, almost all the individual trees are bound to choose the same set of split points thus leading to similar predictions (or) The trees have a high correlation.<br /> \n",
    "To avoid this, the random forest algorithm changes the procedure so that each Decision Tree is limited to a random sample of features of which to search. \n",
    "The number of features that can be searched at each split point (m) must be specified as a parameter to the algorithm.\n",
    "\n",
    "1. For classification a good default is: m = sqrt(p)\n",
    "2. For regression a good default is: m = p/3\n",
    "\n",
    "where p is the total no.of features available.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest - Implementation without sklearn.tree, sklearn.ensemble packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, r2_score, mean_squared_error, roc_auc_score\n",
    "\n",
    "# DecisionTree functions\n",
    "from DecisionTree import DecisionTreeClassifier, DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bootstrap Sampling:\n",
    "\n",
    "In Bootstrap Sampling, the given training dataset X with 'n' samples is used to generate a new training dataset X_new with 'm' samples (m may be equal to n) with *replacement*, such that the set of samples in X_new is always a subset of the set of samples in X.\n",
    "\n",
    "Here, replacement means, each and every sample in X may occur more than once in X_new.\n",
    "\n",
    "\n",
    "#### Function: random.randint()\n",
    "Syntax : randint(start, end)<br />\n",
    "Parameters : (start, end) : Both of them must be integer type values.<br />\n",
    "Returns : A random integer in range [start, end] including the end points.<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrapSampling(X, y, max_samples = None):\n",
    "\n",
    "    '''\n",
    "    X, y - training dataset and labels with 'n' samples\n",
    "    max_samples - maximum no.of samples in the new dataset\n",
    "    '''\n",
    "    \n",
    "    # setting random seed to 0 so that\n",
    "    # the final output doesnt change \n",
    "    # random.seed(0)\n",
    "    \n",
    "    # If max_samples is not given, return the whole training dataset\n",
    "    if not max_samples:\n",
    "        return X, y\n",
    "\n",
    "    # Create two empty lists for X_new and y_new \n",
    "    tempX = []\n",
    "    tempy = []\n",
    "\n",
    "    # Run a while loop max_samples times\n",
    "    while len(tempX) < max_samples:\n",
    "    # BEGIN\n",
    "        \n",
    "        # Choose an index at random between 0 and n\n",
    "        index = random.randint(0, X.shape[0]-1)\n",
    "\n",
    "        # Store the sample present at 'index'\n",
    "        # after converting it into a list \n",
    "        tempSampleX = list(X[index])\n",
    "        tempSampley = y[index]\n",
    "\n",
    "        # Append the local values to the temporary list\n",
    "        tempX.append(tempSampleX)\n",
    "        tempy.append(tempSampley)\n",
    "    # END\n",
    "\n",
    "    # Convert tempX, tempy into numpy arrays \n",
    "    # and store them in X_new, y_new respectively\n",
    "    X_new = np.array(tempX)\n",
    "    y_new = np.array(tempy)\n",
    "    \n",
    "    return X_new, y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 6 1 3 9]\n",
      " [1 9 0 1 3]\n",
      " [4 0 0 8 4]\n",
      " [6 8 6 3 0]\n",
      " [2 6 9 1 0]\n",
      " [1 6 1 3 9]\n",
      " [6 7 7 2 5]\n",
      " [6 7 7 2 5]\n",
      " [8 3 3 2 9]\n",
      " [2 5 8 5 0]]\n",
      "[4 5 5 0 8 4 4 4 9 6]\n"
     ]
    }
   ],
   "source": [
    "#np.random.seed(0)\n",
    "X = np.random.randint(0, 10, (50, 5))\n",
    "y = np.random.randint(0, 10, 50)\n",
    "X_new, y_new = bootstrapSampling(X, y, 10)\n",
    "print(X_new)\n",
    "print(y_new)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest.Fit():\n",
    "\n",
    "This function is used to create 'n_estimators' Decision Trees and train them each on different subsets of the original dataset.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criterion / Cost Function:\n",
    "\n",
    "For Classification:\n",
    "\n",
    "1. 'gini': Gini Index is calculated by subtracting the sum of squared probabilities of each class from one.\n",
    "\n",
    " &nbsp;&nbsp;&nbsp;![alt text](./images/gini.png \"Title\")\n",
    "<br />\n",
    "2. 'entropy': Entropy is the measure of impurity, disorder or uncertainty in a set of samples.\n",
    "\n",
    " &nbsp;&nbsp;&nbsp;![alt text](./images/entropy.png \"Title\")\n",
    "\n",
    "<br />\n",
    "Where, $P_{i}$ is the probability of occurence of class $i$.\n",
    "<br />\n",
    "<br />\n",
    "For Regression:\n",
    "\n",
    "1. 'mse': Mean Squared Error (MSE) of an estimator measures the average of the squares of the errors, i.e, the average squared difference between the estimated values and the actual value.\n",
    "\n",
    " &nbsp;&nbsp;&nbsp;![alt text](./images/mse.png \"Title\")\n",
    "<br />\n",
    "2. 'mae': Mean Absolute Error (MAE) of an estimator measures the average of the absolute errors, i.e, the average absolute difference between the estimated values and the actual value.\n",
    "\n",
    " &nbsp;&nbsp;&nbsp;![alt text](./images/mae.png \"Title\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y, n_estimators = 100, bootstrap = True, max_samples = None, task = 'classification'):\n",
    "    \n",
    "    '''\n",
    "    X, y: Training dataset at labels.\n",
    "    n_estimators: No.of Decision Trees.\n",
    "    bootstrap: Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree.\n",
    "    max_samples: If bootstrap is True, the number of samples to draw from X to train each tree.\n",
    "    task: classification or regression.\n",
    "    '''\n",
    "\n",
    "    # Create an empty list to store n_estimators trees\n",
    "    trees = []\n",
    "\n",
    "    # Run a loop n_esimators times\n",
    "    for i in range(n_estimators):\n",
    "        \n",
    "        # Check if the user wants bootstrap sampling\n",
    "        if bootstrap == True:\n",
    "            \n",
    "            # if yes, create a new training dataset\n",
    "            X_new, y_new = bootstrapSampling(X, y, max_samples)\n",
    "\n",
    "        # Create a Decision tree model based on the type of task specified\n",
    "        if task == 'classification':\n",
    "            tree = DecisionTreeClassifier()\n",
    "        else:\n",
    "            tree = DecisionTreeRegressor()\n",
    "        \n",
    "        # Fit the model\n",
    "        _ = tree.fit(X_new, y_new)\n",
    "        \n",
    "        # Append the model to 'trees'\n",
    "        trees.append(tree)\n",
    "\n",
    "    return trees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest.Predict():\n",
    "\n",
    "This function is used to output the mode of the classes (classification) or mean prediction (regression) of the individual trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useful functions:<br />\n",
    "**np.swapaxes**: (a, axis1, axis2): Interchange two axes of an array.\n",
    "\n",
    "**np.mean**: (a, axis=None, dtype=None, out=None): Compute the arithmetic mean along the specified axis.\n",
    "\n",
    "**np.argmax**: (a, axis=None, out=None): Returns the indices of the maximum values along an axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(trees, X_test, task = 'classification'):\n",
    "\n",
    "    '''\n",
    "    trees: list of individual trees created.\n",
    "    X_test: Test dataset\n",
    "    task: classification or regression\n",
    "    '''\n",
    "\n",
    "    # create a temporary list for storing predictions of individual trees \n",
    "    tempPred = []\n",
    "\n",
    "    # traverse through all the individual trees\n",
    "    # and store the returned predictions in tempPred\n",
    "    for i in trees:\n",
    "        prediction = i.predict(X_test)\n",
    "        tempPred.append(prediction)\n",
    "    \n",
    "    # Convert tempPred into a numpy array\n",
    "    # and swap its axes such that predictions by\n",
    "    # individual trees for one sample\n",
    "    # are present in the same row\n",
    "    tempPred = np.array(tempPred)\n",
    "    tempPred = np.swapaxes(tempPred, 0, 1)\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    # Traverse through all the rows of tempPred\n",
    "    for i in range(tempPred.shape[0]):\n",
    "\n",
    "        # if the task is classification, append\n",
    "        # the mode of all classes present in that row\n",
    "        # to 'predictions'\n",
    "        if task == 'classification':\n",
    "            modeIndex = np.argmax(tempPred[i])\n",
    "            predictions.append(tempPred[i , modeIndex])\n",
    "        \n",
    "        # if the task is regression, append\n",
    "        # the mean of all values present in that row\n",
    "        # to 'predictions' \n",
    "        else:\n",
    "            meanValue = np.mean(tempPred[i])\n",
    "            predictions.append(np.mean(meanValue))\n",
    "    \n",
    "\n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier Class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestClassifier:\n",
    "\n",
    "    def __init__ (self, n_estimators = 100, min_samples_split = 2, max_depth = 5, max_features = None, criterion = 'gini',\n",
    "                  bootstrap = True, max_samples = None):\n",
    "\n",
    "        self.n_estimators = n_estimators\n",
    "        self.min_samples_split = min_samples_split \n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.criterion = criterion\n",
    "        self.bootstrap = bootstrap\n",
    "        self.max_samples = max_samples\n",
    "        self.trees = []\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            \n",
    "            if self.bootstrap == True:\n",
    "                X_new, y_new = bootstrapSampling(X, y, self.max_samples)\n",
    "\n",
    "            tree = DecisionTreeClassifier(self.min_samples_split, self.max_depth, self.max_features, self.criterion)\n",
    "            _ = tree.fit(X_new, y_new)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "        return self.trees\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        predictions = []\n",
    "        tempPred = []\n",
    "\n",
    "        for i in self.trees:\n",
    "            prediction = i.predict(X_test)\n",
    "            tempPred.append(prediction)\n",
    "        \n",
    "        tempPred = np.array(tempPred)\n",
    "        tempPred = np.swapaxes(tempPred, 0, 1)\n",
    "\n",
    "        for i in range(tempPred.shape[0]):\n",
    "            modeIndex = np.argmax(tempPred[i])\n",
    "            predictions.append(tempPred[i , modeIndex])\n",
    "\n",
    "        return np.array(predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestRegressor Class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestRegressor:\n",
    "\n",
    "    def __init__ (self, n_estimators = 100, min_samples_split = 2, max_depth = 5, max_features = None, criterion = 'mse',\n",
    "                  bootstrap = True, max_samples = None):\n",
    "\n",
    "        self.n_estimators = n_estimators\n",
    "        self.min_samples_split = min_samples_split \n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.criterion = criterion\n",
    "        self.bootstrap = bootstrap\n",
    "        self.max_samples = max_samples\n",
    "        self.trees = []\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            \n",
    "            if self.bootstrap == True:\n",
    "                X_new, y_new = bootstrapSampling(X, y, self.max_samples)\n",
    "\n",
    "            tree = DecisionTreeRegressor(self.min_samples_split, self.max_depth, self.max_features, self.criterion)\n",
    "            _ = tree.fit(X_new, y_new)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "        return self.trees\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        predictions = []\n",
    "        tempPred = []\n",
    "\n",
    "        for i in self.trees:\n",
    "            prediction = i.predict(X_test)\n",
    "            tempPred.append(prediction)\n",
    "        \n",
    "        tempPred = np.array(tempPred)\n",
    "        tempPred = np.swapaxes(tempPred, 0, 1)\n",
    "\n",
    "        for i in range(tempPred.shape[0]):\n",
    "            meanValue = np.mean(tempPred[i])\n",
    "            predictions.append(np.mean(meanValue))\n",
    "\n",
    "        return np.array(predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4            5.0           3.6            1.4           0.2  Iris-setosa\n",
       "5            5.4           3.9            1.7           0.4  Iris-setosa\n",
       "6            4.6           3.4            1.4           0.3  Iris-setosa\n",
       "7            5.0           3.4            1.5           0.2  Iris-setosa\n",
       "8            4.4           2.9            1.4           0.2  Iris-setosa\n",
       "9            4.9           3.1            1.5           0.1  Iris-setosa"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('iris_dataset.csv')\n",
    "\n",
    "# drop unnecessary columns \n",
    "df.drop(columns = ['Id'], inplace = True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Split Test and Train Datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a classifier model\n",
    "classifier_model = RandomForestClassifier(n_estimators=10, bootstrap=True, max_samples=60)\n",
    "# Other parameters such as max_depth, criterion, etc can be added too\n",
    "\n",
    "# Fit the model with X_train, y_train\n",
    "_ = classifier_model.fit(X_train, y_train)\n",
    "# '_' is added as a throwaway variable, i.e, it is used to suppress\n",
    "# any output that may be returned by the function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call predict function\n",
    "y_pred = classifier_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        11\n",
      "Iris-versicolor       1.00      1.00      1.00        13\n",
      " Iris-virginica       1.00      1.00      1.00         6\n",
      "\n",
      "       accuracy                           1.00        30\n",
      "      macro avg       1.00      1.00      1.00        30\n",
      "   weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0  6]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.075</td>\n",
       "      <td>13.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.069</td>\n",
       "      <td>15.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.9964</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.065</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.073</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.57</td>\n",
       "      <td>9.5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.071</td>\n",
       "      <td>17.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.80</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "5            7.4              0.66         0.00             1.8      0.075   \n",
       "6            7.9              0.60         0.06             1.6      0.069   \n",
       "7            7.3              0.65         0.00             1.2      0.065   \n",
       "8            7.8              0.58         0.02             2.0      0.073   \n",
       "9            7.5              0.50         0.36             6.1      0.071   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "5                 13.0                  40.0   0.9978  3.51       0.56   \n",
       "6                 15.0                  59.0   0.9964  3.30       0.46   \n",
       "7                 15.0                  21.0   0.9946  3.39       0.47   \n",
       "8                  9.0                  18.0   0.9968  3.36       0.57   \n",
       "9                 17.0                 102.0   0.9978  3.35       0.80   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  \n",
       "5      9.4        5  \n",
       "6      9.4        5  \n",
       "7     10.0        7  \n",
       "8      9.5        7  \n",
       "9     10.5        5  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('winequality.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In RandomForest algorithm, there is no need to standardise data since features are in no way inter dependent.\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Split Test and Train Datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a regressor model\n",
    "regressor_model = RandomForestRegressor(n_estimators=10, bootstrap=True, max_samples=50)\n",
    "# Other parameters such as max_depth, criterion, etc can be added too\n",
    "\n",
    "# Fit the model with X_train, y_train\n",
    "_ = regressor_model.fit(X_train, y_train)\n",
    "# '_' is added as a throwaway variable, i.e, it is used to suppress\n",
    "# any output that may be returned by the function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Call predict function\n",
    "y_pred = regressor_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2714022517911977\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41709374999999993\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest - Implementation with sklearn.tree, sklearn.ensemble packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4            5.0           3.6            1.4           0.2  Iris-setosa\n",
       "5            5.4           3.9            1.7           0.4  Iris-setosa\n",
       "6            4.6           3.4            1.4           0.3  Iris-setosa\n",
       "7            5.0           3.4            1.5           0.2  Iris-setosa\n",
       "8            4.4           2.9            1.4           0.2  Iris-setosa\n",
       "9            4.9           3.1            1.5           0.1  Iris-setosa"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing sklearn's RandomForestClassifier package\n",
    "# as Rfc to avoid confusion\n",
    "from sklearn.ensemble import RandomForestClassifier as Rfc\n",
    "\n",
    "df = pd.read_csv('iris_dataset.csv')\n",
    "\n",
    "# drop unnecessary columns \n",
    "df.drop(columns = ['Id'], inplace = True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Split Test and Train Datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a classifier model\n",
    "classifier_model = Rfc(n_estimators=10, bootstrap=True, max_samples=60)\n",
    "# Other parameters such as max_depth, criterion, etc can be added too\n",
    "\n",
    "# Fit the model with X_train, y_train\n",
    "_ = classifier_model.fit(X_train, y_train)\n",
    "# '_' is added as a throwaway variable, i.e, it is used to suppress\n",
    "# any output that may be returned by the function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        11\n",
      "Iris-versicolor       0.93      1.00      0.96        13\n",
      " Iris-virginica       1.00      0.83      0.91         6\n",
      "\n",
      "       accuracy                           0.97        30\n",
      "      macro avg       0.98      0.94      0.96        30\n",
      "   weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  1  5]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.075</td>\n",
       "      <td>13.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.069</td>\n",
       "      <td>15.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.9964</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.065</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.073</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.57</td>\n",
       "      <td>9.5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.071</td>\n",
       "      <td>17.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.80</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "5            7.4              0.66         0.00             1.8      0.075   \n",
       "6            7.9              0.60         0.06             1.6      0.069   \n",
       "7            7.3              0.65         0.00             1.2      0.065   \n",
       "8            7.8              0.58         0.02             2.0      0.073   \n",
       "9            7.5              0.50         0.36             6.1      0.071   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "5                 13.0                  40.0   0.9978  3.51       0.56   \n",
       "6                 15.0                  59.0   0.9964  3.30       0.46   \n",
       "7                 15.0                  21.0   0.9946  3.39       0.47   \n",
       "8                  9.0                  18.0   0.9968  3.36       0.57   \n",
       "9                 17.0                 102.0   0.9978  3.35       0.80   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  \n",
       "5      9.4        5  \n",
       "6      9.4        5  \n",
       "7     10.0        7  \n",
       "8      9.5        7  \n",
       "9     10.5        5  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing sklearn's RandomForestRegressor package\n",
    "# as Rfr to avoid confusion\n",
    "from sklearn.ensemble import RandomForestClassifier as Rfr\n",
    "\n",
    "df = pd.read_csv('winequality.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In RandomForest algorithm, there is no need to standardise data since features are in no way inter dependent.\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Split Test and Train Datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a regressor model\n",
    "regressor_model = Rfr(n_estimators=10, bootstrap=True, max_samples=50)\n",
    "# Other parameters such as max_depth, criterion, etc can be added too\n",
    "\n",
    "# Fit the model with X_train, y_train\n",
    "_ = regressor_model.fit(X_train, y_train)\n",
    "# '_' is added as a throwaway variable, i.e, it is used to suppress\n",
    "# any output that may be returned by the function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call predict function\n",
    "y_pred = regressor_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.022859092459911245\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.559375\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}